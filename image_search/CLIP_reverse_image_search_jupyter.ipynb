{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2XOduVd9xRiH",
    "outputId": "a48eb9be-dbff-4ed7-bd9e-7f900c9ddad5"
   },
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B_QzsJRgPJud",
    "outputId": "890e3053-1784-4d3d-dc21-365b1bada9ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saurav/base_env/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import clip\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from google.colab import drive\n",
    "\n",
    "#loading CLIP MODEL and preprocessing function\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "WcSE7uRCV-3A",
    "outputId": "197c8c73-94a5-4c40-ad6f-d9dd56f0fb26"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>masterCategory</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>articleType</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>usage</th>\n",
       "      <th>productDisplayName</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15970</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Shirts</td>\n",
       "      <td>Navy Blue</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Turtle Check Men Navy Blue Shirt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39386</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Peter England Men Party Blue Jeans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59263</td>\n",
       "      <td>Women</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2016</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Titan Women Silver Watch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21379</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Track Pants</td>\n",
       "      <td>Black</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Manchester United Men Solid Black Track Pants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53759</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Tshirts</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Puma Men Grey T-shirt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44442</th>\n",
       "      <td>17036</td>\n",
       "      <td>Men</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Casual Shoes</td>\n",
       "      <td>White</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2013</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Gas Men Caddy Casual Shoe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44443</th>\n",
       "      <td>6461</td>\n",
       "      <td>Men</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>Flip Flops</td>\n",
       "      <td>Flip Flops</td>\n",
       "      <td>Red</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2011</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Lotto Men's Soccer Track Flip Flop</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44444</th>\n",
       "      <td>18842</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Tshirts</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Puma Men Graphic Stellar Blue Tshirt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44445</th>\n",
       "      <td>46694</td>\n",
       "      <td>Women</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Fragrance</td>\n",
       "      <td>Perfume and Body Mist</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2017</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Rasasi Women Blue Lady Perfume</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44446</th>\n",
       "      <td>51623</td>\n",
       "      <td>Women</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2016</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Fossil Women Pink Dial Chronograph Watch ES3050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44447 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id gender masterCategory subCategory            articleType  \\\n",
       "0      15970    Men        Apparel     Topwear                 Shirts   \n",
       "1      39386    Men        Apparel  Bottomwear                  Jeans   \n",
       "2      59263  Women    Accessories     Watches                Watches   \n",
       "3      21379    Men        Apparel  Bottomwear            Track Pants   \n",
       "4      53759    Men        Apparel     Topwear                Tshirts   \n",
       "...      ...    ...            ...         ...                    ...   \n",
       "44442  17036    Men       Footwear       Shoes           Casual Shoes   \n",
       "44443   6461    Men       Footwear  Flip Flops             Flip Flops   \n",
       "44444  18842    Men        Apparel     Topwear                Tshirts   \n",
       "44445  46694  Women  Personal Care   Fragrance  Perfume and Body Mist   \n",
       "44446  51623  Women    Accessories     Watches                Watches   \n",
       "\n",
       "      baseColour  season  year   usage  \\\n",
       "0      Navy Blue    Fall  2011  Casual   \n",
       "1           Blue  Summer  2012  Casual   \n",
       "2         Silver  Winter  2016  Casual   \n",
       "3          Black    Fall  2011  Casual   \n",
       "4           Grey  Summer  2012  Casual   \n",
       "...          ...     ...   ...     ...   \n",
       "44442      White  Summer  2013  Casual   \n",
       "44443        Red  Summer  2011  Casual   \n",
       "44444       Blue    Fall  2011  Casual   \n",
       "44445       Blue  Spring  2017  Casual   \n",
       "44446       Pink  Winter  2016  Casual   \n",
       "\n",
       "                                    productDisplayName Unnamed: 10 Unnamed: 11  \n",
       "0                     Turtle Check Men Navy Blue Shirt         NaN         NaN  \n",
       "1                   Peter England Men Party Blue Jeans         NaN         NaN  \n",
       "2                             Titan Women Silver Watch         NaN         NaN  \n",
       "3        Manchester United Men Solid Black Track Pants         NaN         NaN  \n",
       "4                                Puma Men Grey T-shirt         NaN         NaN  \n",
       "...                                                ...         ...         ...  \n",
       "44442                        Gas Men Caddy Casual Shoe         NaN         NaN  \n",
       "44443               Lotto Men's Soccer Track Flip Flop         NaN         NaN  \n",
       "44444             Puma Men Graphic Stellar Blue Tshirt         NaN         NaN  \n",
       "44445                   Rasasi Women Blue Lady Perfume         NaN         NaN  \n",
       "44446  Fossil Women Pink Dial Chronograph Watch ES3050         NaN         NaN  \n",
       "\n",
       "[44447 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drive.mount('/content/drive')\n",
    "# DATA_PATH = \"/content/drive/MyDrive\"\n",
    "DATA_PATH = '/home/saurav/Documents'\n",
    "\n",
    "csv_file = DATA_PATH+'/required_dataset/styles2.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "q9ugSGqohTjp"
   },
   "outputs": [],
   "source": [
    "#defining image paths and files\n",
    "image_folder = DATA_PATH+'/required_dataset/images'\n",
    "embeddings = {}\n",
    "batch_size = 8\n",
    "total_rows = len(df)\n",
    "checkpoint_file = \"clip_embeddings_checkpoint.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "I3RgIGA-huqO"
   },
   "outputs": [],
   "source": [
    "#function to combine text features from multiple columns\n",
    "def create_text_description(row):\n",
    "  columns = [\n",
    "      str(row['gender']),\n",
    "      str(row['masterCategory']),\n",
    "      str(row['subCategory']),\n",
    "      str(row['articleType']),\n",
    "      str(row['baseColour']),\n",
    "      str(row['season']),\n",
    "      str(row['year']),\n",
    "      str(row['usage']),\n",
    "      str(row['productDisplayName'])\n",
    "  ]\n",
    "  #concatinating all relevant columns into single description\n",
    "  #as join only supports string so converted all column values to str to avoid null and integer data types\n",
    "  return ' '.join(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vaTflS3omK_t"
   },
   "outputs": [],
   "source": [
    "#iterating through CSV rows to generate embeddings for each ID\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "  image_id = str(row['id'])\n",
    "  #combine multiple columns into one descriptive text\n",
    "  text_description = create_text_description(row)\n",
    "\n",
    "  #process the text to get text embeddings\n",
    "  text_input = clip.tokenize([text_description]).to(device)\n",
    "  with torch.no_grad():\n",
    "    text_embedding = model.encode_text(text_input).cpu().numpy()\n",
    "\n",
    "  #load and preprocess image corresponding to 'id'\n",
    "  image_path = os.path.join(image_folder, f\"{image_id}.jpg\")\n",
    "  if os.path.exists(image_path):\n",
    "    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "      image_embedding = model.encode_image(image).cpu().numpy()\n",
    "\n",
    "  else:\n",
    "    print(f\"Image not found for ID: {image_id}\")\n",
    "    image_embedding = None\n",
    "\n",
    "  #store embeddings in a dictionary\n",
    "  embeddings[image_id] = {\n",
    "      'text_embedding': text_embedding,\n",
    "      'image_embedding': image_embedding\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "g6Xoy0pye8L5",
    "outputId": "921d5d1e-d0eb-445f-866a-1345d991b994"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████████████▎                                                                                                                             | 837/5556 [22:18<2:02:58,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 39403.jpg not found, skipping image embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████████████████████▍                                                                                                                | 1303/5556 [34:38<1:50:46,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image l.jpg not found, skipping image embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████████████████████████████▌                                                                                             | 2026/5556 [54:10<1:32:29,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 39410.jpg not found, skipping image embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 4040/5556 [1:47:05<39:23,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 39401.jpg not found, skipping image embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 4550/5556 [2:00:30<25:34,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 39425.jpg not found, skipping image embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 5003/5556 [2:12:29<13:44,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 12347.jpg not found, skipping image embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌         | 5200/5556 [2:17:39<09:10,  1.55s/it]"
     ]
    }
   ],
   "source": [
    "# Process the data in batches\n",
    "for start_idx in tqdm(range(0, total_rows, batch_size)):\n",
    "    end_idx = min(start_idx + batch_size, total_rows)\n",
    "    batch = df.iloc[start_idx:end_idx]\n",
    "\n",
    "    # Batch processing text descriptions\n",
    "    text_descriptions = [create_text_description(row) for _, row in batch.iterrows()]\n",
    "    text_inputs = clip.tokenize(text_descriptions).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        text_embeddings = model.encode_text(text_inputs).cpu().numpy()\n",
    "\n",
    "    # Batch processing images\n",
    "    image_embeddings = []\n",
    "    for _, row in batch.iterrows():\n",
    "        image_id = str(row['id'])\n",
    "        image_path = os.path.join(image_folder, f\"{image_id}.jpg\")\n",
    "\n",
    "        if os.path.exists(image_path):\n",
    "            image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                image_embedding = model.encode_image(image).cpu().numpy()\n",
    "            image_embeddings.append(image_embedding)\n",
    "        else:\n",
    "            print(f\"Image {image_id}.jpg not found, skipping image embedding.\")\n",
    "            image_embeddings.append(None)\n",
    "\n",
    "    # Store embeddings for the current batch\n",
    "    for i, (_,row) in enumerate(batch.iterrows()):\n",
    "        image_id = str(row['id'])\n",
    "        embeddings[image_id] = {\n",
    "            \"text_embedding\": text_embeddings[i],\n",
    "            \"image_embedding\": image_embeddings[i]\n",
    "        }\n",
    "\n",
    "# Save embeddings to a pickle file\n",
    "output_file = \"clip_embeddings_batch.pkl\"\n",
    "with open(output_file, 'wb') as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "\n",
    "print(f\"Embeddings have been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lTeYAxGVROYY"
   },
   "outputs": [],
   "source": [
    "#preprocessing the image\n",
    "image_path = (DATA_PATH+'/dataset/random_test_images/lehenga.png')\n",
    "\n",
    "#.to(device) method moves the image tensor to the specified computing device either CPU or GPU\n",
    "image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQ8KVajcO-vL"
   },
   "outputs": [],
   "source": [
    "#Encode the  image into CLIP's embedding space\n",
    "with torch.no_grad():\n",
    "  image_features = model.encode_image(image)\n",
    "\n",
    "#normalize the calculated embeddings\n",
    "image_features /=  image_features.norm(dim = -1, keepdim = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThTzveBXmox-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
